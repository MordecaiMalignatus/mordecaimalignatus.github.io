---
layout: post
author: Mordecai
title: "Systems Modelling for better mental health"
date: Sat, 30 Oct 2021 23:31:09 +0200
categories: post
---

I recently read _Engineering A Safer World_[^1] by Nancy Leveson[^2], and while
it is intended about how to make systems safe for the people running them, I
can't help but notice that so many of the tools, structures, assumptions and
structures given hold up for the personal life, too. The benefit of the theory
of the really abstract (like systems theory is) is that you can apply it to a
lot of things. So, an application of systems theory to a personal life impeded
by mental illness and life in These Days.[^9]

## The definition of Safety in the context of running your own life.

Traditionally, *Safety* means that a system does not do harm to people. In the
system of yourself, operating in the world as it is today, it means not letting
*yourself* come to harm. The same techniques used for eliminating unacceptable
losses in complex systems hold for personal lives, seeing as you are a person in
a complex system: Society. This means we can steal a lot of tools that have been
developed with the urgency and importance of saving lives for saving our own.

Of course, if we consider society the system under scrutiny, we are not going to
get far, society at large is far outside of our influence. Instead, let us draw
a smaller boundary: One person's life, your own. There is considerable discourse over
whether or not one person's life is considered "controllable", but, in the
interest of time, let us settle for "you have some degree of influence over your
own life".

## Hazards

Now, we can start applying from the toolbox. First up, the identification of
hazards.

A *hazard* is anything that, under a certain event, produces an accident, a
loss, something going wrong that you'd really rather didn't. Some of these are
always present but not helpful to include in a list intended to mitigate them.
(being outside comes with the small-but-present risk of being mauled by a bear)

The things that fall into this in our context are what are typically considered
*symptoms*, things like:

- Poor sleep or insomnia,
- Insufficient/bad/excessive eating,
- Substance-based coping (drinking, smoking, weed, etc)

It should be pointed out that all these are not harmful for themselves. They may
be not fun to go through, not exactly wonderful to experience, but only in the
most extreme forms do they do acute harm by themselves. Substance-based coping
*still achieves its main goal*, coping with the broader context in life.

However, all of them open up the possibility of things going more wrong than if
they were not present. Lack of sleep produces lapses in attention and cognitive
capacity that can be mostly fine, but deadly when combined with driving a car.
Smoking is a fine coping mechanism for stress until your lung capacity matters,
or you develop cancer from continued exposure.

This increased potential for things going wrong is why we want to keep an eye
out for them: If we can avoid these being present in our life, less things have
a possibility of causing an unacceptable loss, and so less things will go
acutely wrong. (or, in the parlance these principles are nicked from, cause an
accident)

## Incident Analyses

This is where the second part comes in, the *incident analyses*. That means,
you'll almost certainly remember situations, encounters, missed opportunities
that you wish had gone different. Fights you've had where you felt like an idiot
the entire way through because you were fighting tooth and nail for something
you didn't care about much in the first place. Health problems that arose from
coping mechanisms having harmful side effects. From these situations you can
then learn about your behaviour, how you react, what you do, how you see the
world, and how you prioritise.

What makes this different, and worthwhile, is that the information you find in
these about your own behaviour is not in the hypothetical "this is what I think
I'd do" set of behavioural trait an idealised you exhibits, but in the "this
actually happened" set of behaviours of the tired, cranky and ill you that has
to deal with life on a daily basis. This is the person that others are talking
to, and the person that forms your broader context.

### An Aside About Managing Your Own Psychology

It should be noted here, that since we are so far looking exclusively at things
that have gone wrong here, and we see "things that actually happened" as a more
real version of how you prioritise, act, and decide in the moment than what you
tell yourself in the moment, this can and will clash sharply with your own
self-conception, of how you act. This can, and will, be painful. It's of
absolutely utmost importance that you do not beat yourself up about this, as
much as you can manage not to. Blame, judgement, and disciplinary 'punishment'
is absolutely antithetical to the entire process, and will make most of the
benefits of it vanish into a puff of misery, but more on this in a bit.

While this is an immensely useful toolbox, its usual (and common) focus on the
negative takes a large psychological toll and therefore has a sort of "you must
be this well to participate" barrier to entry.

You can and absolutely should apply the same techniques to things you think went
well, things that left you feeling warm and fuzzy on the inside. The result will
be the same, but with encouragement of the environmental circumstances rather
than management or avoidance.

The general guideline is, when something went very differently than you planned,
foresaw, or thought it would go, it makes for a great context to put into this
process. I would advise that if you are currently battling intense depression or
similarly intense illness to focus on the things that went better than expected.
There is just as much to learn there, about how you act and decide and
prioritise, and it won't make you feel worse about yourself, you've got plenty
of that to go around already.

## A Worked Example: A Fight With A Friend.

Consider now what happened in this specific interaction. Things did not go as
you planned: "I erupted at my friend and now they're hurt and I feel terrible".

There is the obvious first layer here: I erupted at my friend, that is bad and I
should never do this. In order to achieve this, you begin to view anger as
suspicious, frustration as suspicious, and tamp down on any displayed negative
emotions. This attempted fix for the situation has now made your life *worse*,
as you suppress your own emotions.

Instead, I would encourage you to look at what needed to be present in order for
this to happen:

- You were feeling irritable and frustrated.
- You were talking to your friend.
- Your friend poked at something that you were feeling very self-conscious
  about.

It took all three of these factors to produce the situation, any combination of
two out of three would not have been sufficient, and would not have resulted in
the problem. Two of those involve things that your friend had nothing to do
with, but were nonetheless necessary for this to happen: Congratulations, you've
identified hazards!

You now have mitigation strategies for preventing situations like this from
happening again:

- Find ways to cope with irritability and frustration before it gets exposed to
  other people and potentially results in this.[^8]
- Talk to said friend about this particular topic, ask to avoid it, or to make
  it clear in a way that the same comment/situation does not repeat.
- A step further that comes with more effort and is only worth it if the topic
  has caused issues repeatedly: Sit down and figure out a way you can defuse it.
  Attend therapy, read books, etc.[^10]
- Cancel on your friend when you are feeling irritable and frustrated, as a last
  resort.

After this, you can "zoom out", and focus on the next level upwards. Why were
you frustrated? Is it a regular occurrence? What causes it? How can you get
better at dealing with it? Why did your friend poke at this specific thing? Has
it been a problem in the past? How is your relationship with this friend? And so
on. Each question will yield understanding over how you work and behave, and you
can learn about yourself and your own behaviours.

You should write down the questions you ask, and the answers you find in
someplace private. Being able to reference what has happened in the past is
invaluable to finding patterns, and you are indeed no exception to this. The
guiding principle is a gentle curiosity. How do things work, why do they work?
What has led them to be like this? There's no wrong answers here, merely
explanations for how things came to be, and maybe also how they work.

A tempting thought, at this point, is to feel terrible: You are to blame for
this situation! If you had just been different, this all could have been
avoided. And so, a note on blame, safety, and humans in complex systems.

## Systems Design and Operator Error

An early, wonderful line in _Engineering A Safer World_ (p. 39) is this:

> All human activity takes place within and is influenced by the environment,
> both physical and social, in which it takes place. It is, therefore, often
> very difficult to separate system design error from operator error: In highly
> automated systems, the operator is often at the mercy of the system design and
> operational procedures.

This has a few implications, but the big three are:

1. The environment around you shapes your actions to the degree that any active
   mistake made is mitigatable by your environment, and
2. Your actions are *well-reasoned* in your context and view on the world, and
   therefore
3. That your decisions *are not to blame*.

To unpack this, let's think about the environment the standard operator that
Leveson is talking about. They're controlling a power plant, or some other
industrial process. They have to navigate controlling an extremely complex
system by their own mental models of this system, informed by the (necessarily
limited) feedback available to them, and can only affect change on this system
by some limited set of actions.

To dig out an old favourite of Safety Engineering nerds, let's talk about the
[Three Mile Island Accident][three-mile-island-wiki]. Many, many analyses, talks
and papers have been written about this, but to be usefully reductive about it,
it came down to a few factors: The sensor they were acting on did not indicate
what the operators thought it indicated (it merely indicated if the valve had
been supplied power, not that it actually had closed), the situation they found
themselves in was never covered in training procedures (but also looked a **lot**
like something they had been trained to *never* let happen), and the feedback
the system was giving them was, to them, contradictory. Their actions, of trying
to diagnose the problem, and their confusion over *whether there even was a
problem to begin with* is perfectly understandable from their contexts as the
event was unfolding.

That, in hindsight, we can see how other indicators could, in theory, have
prevented any damage from being incurred whatsoever, is a meaningless
counterfactual whose main use it is to dictate how people *should have
behaved*/admonish/blame. For their context, their information, situation and
knowledge, they behaved as rationally as they could. To go on and on about
things that *did not happen* (counter-factuals) is meaningless, and worse,
harmful.

Blame, in general, only makes things worse. It's an understandable human
instinct: Blame exists to discharge pain, discomfort, guilt. There's a single
responsible person, and if we can blame them, that means that are aren't to
blame for this. We avoid the pain and discharge it to someone else instead.

But doing so does nothing to actually address the problem. If someone else is to
blame, and we definitely are not, then our actions haven't contributed to the
problem, and therefore there is no need to change our actions, our environment.
Blame *reduces* our chances to learn from what happened. This is how you end up
with some sytems produces monthly occurrences of "unpreventable and tragic
instances of human error". Nothing about it was unpreventable, but to recognise
would mean to do away with the guilt-and-pain-discharging application of blame.

So, let's talk about the thing we *can* actually do: Shape our environment to
prevent, mitigate, or lessen hazards that we encounter. Because if
"unpreventable and tragic human error" happens repeatedly, the environment is
the thing in common between those.

## Environment Design

Our environment is the world we exist in. It presents us events in a certain
way, to which we then react. We can change the ways in which events and facts
are presented to us, and therefore change our reaction.

You can see how this very minimal definition of "environment design" is both,
immensely powerful and absolutely unhelpful.

The core helpfulness comes from shifting the need for attention and planning
from when we can afford to spare it (times of quiet and rest with little demand
on our facilities) to those when we can't (When we have problems to solve, like
when we are late, or need to think through a problem, or are talking to people).

The main principle here is the direction of *attention*, from the you that has
the time and space to think through what we need in those situations where we
face the pressures of getting something done. We can think about ourselves in
the situations where our environment led to our attention being misdirected, and
see if we can't change that to the better. What are the things we need to see in
the moment? How do we select for only seeing what matters when we are *doing
things*?

For example, one of the simplest ways in which you can design your environment
to shift attention and consideration is locality: If you are prone to forgetting
your lunch, putting it next to the door to grab easily when you are rushing out
of the door makes you less prone to forgetting your lunch.

This is also where the analyses come in, what went wrong, where? These point to
weaknesses in the environment setup, and these usually surprise is – our
planning, thoughtful self did not anticipate those things become problems.
That's both, perfectly okay, and completely expected. What we select for in calm
and quiet is never the same as what we select for when in the context of doing
things.

But environment design needs to be done carefully. We don't fully control our
environment, but we can influence it. One particular failure mode I've run into
with this model is, well, if I can setup my environment to avoid this, this
means that not doing so is my mistake yet again and I've fucked it up, *again*.
This is not helpful, and will just make you feel worse. The enviroment is not
totally under your control. But you can influence it, carefully.r

## The Cycle Of Error

Something to be aware of when you do actively influence your environment (and to
beware of) is what Dr. Cook called *The Cycle of Error*: A bad thing happens. We
look at the bad thing, and find that it was caused by a person misjudging
something, doing something wrong, missing something crucial in their evaluation.
In other words, "Human Error". Then we Fix This™. This is usually done via
process, by special-casing this somehow. We add an item to a checklist. We have
Fixed The Issue™.

But in doing so we've made the system more complex. There's now an additional
item to pay attention to. Because the fix was intended to fix one specific
issue, that's the only thing it has been evaluated against, while in many more
other circumstances it may now be a problem. Then, for a while, nothing
happens. We feel assured in our correction of the problem.

Then, one of the situations arises where the correction is actually in the
way. Either the person is able to cope with the increased complexity and is able
to disregard the correction when it is appropriate (which will go unrecognised,
since the correction happening has not resulted in anything visible), or the
correction causes a bad thing to happen, and we again, Fix This™. You can see
where this is going.

This is particularly pernicious in situations where it's people dealing with
people, and an edge case crops up. People (especially engineers are prone to
this) rush to fix the edge case with additional process, but the cost of the
additional complexity in process is so much higher than the problem it solves.
[Jacob Kaplan-Moss][jkm-story] recently made this point better than I would in
this paragraph.

## Economic pressures and depression

### TODO Notes

- Instead of economic pressures pulling us away from safety it's depression and
  lack of energy
  - Given that both, economic pressures and depression result in "do more with
    less" actions, they are roughly equatable.
- Even without depression, the same factors are still present. We want to spend
  less time on things like this. We want to spend more time doing the things we
  enjoy. We want to be generally happier.

### Draft

One of the many reasons as to why the world is so hard to deal with – I would
argue one of the central ones – is that complex systems are dynamic. They adapt
to the pressures they face. In abstract, big systems that are studied like this,
the pressures are economic: The system costs too much money, the system doesn't
produce enough, the system hurts too many people.[^6]

And so the system adapts. The people contained within find ways of adapting to
those pressures. They find ways to be safer, cheaper, faster. The system, first
of it all, optimises for its own continued existence. Everything else comes
second. The problem is that applying these pressures will produce consequences
that are usually not foreseen, or intended, by the parts that apply these
pressures. Pressuring a system to be cheaper will result in adaptations that
The Powers That Be would consider "cut corners".

The second part to this adaptation and complexity is the _Law Of Stretched
Systems_. In terms of the above, if you have a system with 'spare capacity',
i.e. a system that could produce more, then the pressure towards efficiency will
demand that production. And it will demand more, and more, until all of that
spare capacity is used up, and the system is just, just on the verge of being
too expensive, too slow, too dangerous. Now, any further capacity, any slack you
add to the system and don't have a means of defending with tooth and nail will
instantly be eaten up by this demand. After all, the factory owner asks himself,
why make less money?

TODO

## Why Would I Do This, A Coda

I'm aware this is an unusual angle to take for debugging your own life. I'm
aware it's mechanistic, oddly robotic, and detached. That is in fact, why I
recommend this to anyone seeking better understanding of their life:

- The process being mechanistic and checklist-able means that I was able to
  follow it even at my most depressed,
- The detachment allowed me to avoid my own biases towards myself, I was able to
  just treat myself as another person, a difficult task at times.

I do actually recommend this process widely, by applying it to just 1-2 things
that have happened recently, you may be able to gain insight into things you
were not aware of previously.

---

[^1]: This is a fantastic book, and it's even accessible for free under [the
    Open Access programme][easw-pdf] from MIT Press. Read it, particularly Part
    I is some of the best writing on what it means to engineer I've seen.

[^2]: Caveat for the well-read reader: The field is a lot bigger than that, and
    in particular she seems to have a distinction between systems design and
    systems operation that most of the field does not seem to share. In that, my
    view on this may be limited.

[^4]: Removing myself from consideration and instead considering it an abstract
    person running someone's life (depersonalising it) helped me apply the
    empathy I feel towards people in the abstract, but not necessarily always to
    myself. The same might apply to you.

[^5]: Of which one of the better books on accident modelling happens to be
    *Engineering A Safer World*!

[^6]: Well-read readers will recognise this as the boundaries in Rasmussen's
    Dynamic Safety model, which is usually the model of choice to demonstrate
    how systemic factors in dynamic systems combine to failures.

[^7]: This is something that actually has reached mainstream awareness, in form
    of the now-relatively-well-known term "Psychological Safety", or feeling
    safe to voice your opinions and feedback.

[^8]: While this requires an awareness of your emotions that you may not have to
    this degree, you can then also add the required hazard of "I was unaware I
    was frustrated and irritable", which instead has the mitigation strategy of
    finding ways to take more accurate stock of your emotions.

[^9]: Why this post? I have no other motivation, other than I could successfully
    adapt and apply quite a few techniques to my daily life, and I want to
    share. Between depression, recently-treated ADHD, and PTSD, life is not
    always the easiest, and I will take help from any corner I can.

[^10]: Please don't take this to mean that you are to blame for this reaction,
    or that it "shouldn't even be a problem", or that it's bad to be angry at
    what the topic. I mean this purely in the sense of, if you can find ways to
    avoid being annoyed, you end up less annoyed. For me, one of these cases was
    a direct trigger for my PTSD and I lashed out in consequence. Should I have
    been angry? Yes. But it also hurt people that did nothing to contribute to
    my pain, and hurting them did nothing to lessen my pain. Learning how to
    defuse that made my life better.

[easw-pdf]: https://direct.mit.edu/books/book/2908/Engineering-a-Safer-WorldSystems-Thinking-Applied
[three-mile-island-wiki]: https://en.wikipedia.org/wiki/Three_Mile_Island_accident
[jkm-story]: https://jacobian.org/2022/feb/14/that-wild-aam-story/

### Draft Notes

- Remember, the purpose of a system is what it does, there is no inherent virtue
  in what is happening now, and tinkering with it might only yield benefits.
