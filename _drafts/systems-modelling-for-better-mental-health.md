---
layout: post
author: Mordecai
title: "Systems Modelling for better mental health"
date: Sat, 30 Oct 2021 23:31:09 +0200
categories: post
---

I recently read _Engineering A Safer World_[^1] by Nancy Leveson[^2], and while
it is intended about how to make systems safe for the people running them, I
can't help but notice that so many of the tools, structures, assumptions and
structures given hold up for the personal life, too. The benefit of the theory
of the really abstract (like systems theory is) is that you can apply it to a
lot of things. So, an application of systems theory to a personal life impeded
by mental illness and life in These Days.[^9]

## The definition of Safety in the context of running your own life.

Traditionally, *Safety* means that a system does not do harm to people. In the
system of yourself, operating in the world as it is today, it means not letting
*yourself* come to harm. The same techniques used for eliminating unacceptable
losses in complex systems hold for personal lives, seeing as you are a person in
a complex system: Society. This means we can steal a lot of tools that have been
developed with the urgency and importance of saving lives for saving our own.

Of course, if we consider society the system under scrutiny, we are not going to
get far, society at large is far outside of our influence. Instead, let us draw
a smaller boundary: One person's life. In doing so, we can start applying from
the toolbox, first up, the identification of hazards.

A *Hazard* is anything that, under a certain event, produces an accident, a
loss, something going wrong that you'd really rather didn't. Some of these are
always present but not helpful (being outside comes with the small-but-present
risk of being mauled by a bear). There are a lot of hazards, but only some of
them are useful to consider in this light.

## Incident Analyses

This is where the second part comes in, the *incident analyses*. That means,
you'll almost certainly remember situations, encounters, missed opportunities
that you wish had gone different. From these situations you can then learn about
your behaviour, and not in the hypothetical "this is what I think I'd do" set of
behavioural trait an idealised you exhibits, but in the "this actually happened"
set of behaviours of the tired, cranky and ill you that has to deal with life on
a daily basis.

It should be noted here, that since we are so far looking exclusively at things
that have gone wrong here, the picture painted of yourself will be focused
towards the less-great parts of you and your behaviour. This is not the whole
truth! You can apply the same techniques to things you think went well, things
that left you feeling warm and fuzzy on the inside. The result will be the same,
but with encouragement of the environmental circumstances rather than management
or avoidance.

Consider now what happened in this specific interaction. Things did not go as
you planned: "I erupted at my friend and now they're hurt and I feel terrible".

There is the obivous first layer here: I erupted at my friend, that is bad and I
should never do this. In order to achieve this, you begin to view anger as
suspicious, frustration as suspicious, and tamp down on any displayed negative
emotions. This attempted fix for the situation has now made your life *worse*,
as you suppress your own emotions.

Instead, I would encourage you to look at what needed to be present in order for
this to happen:

- You were feeling irritable and frustrated.
- You were talking to your friend.
- Your friend poked at something that you were feeling very self-conscious
  about.

It took all three of these factors to produce the situation, any combination of
two out of three would not have been sufficient, and would not have resulted in
the incident. Congratulations, you've identified hazards!

You now have mitigation strategies for preventing situations like this from
happening again:

- Find ways to cope with irritability and frustration before it gets exposed to
  other people and potentially results in this.[^8]
- Talk to said friend about this particular topic, ask to avoid it, or to make
  it clear in a way that the same comment/situation does not repeat.
- Do something with your friend that involves less direct discussion: See a
  movie, invite other friends, play a game, etc.
- Cancel on your friend when you are feeling irritable and frustrated, if you
  can't see other strategies working.

After this, you can "zoom out", and focus on the next level upwards. Why were
you frustrated? Is it a regular occurrence? What causes it? How can you get
better at dealing with it? Why did your friend poke at this specific thing? Has
it been a problem in the past? How is your relationship with this friend? And so
on. Each question will yield understanding over how you work and behave, and you
can learn about yourself and your own behaviours.

You should write down the questions you ask, and the answers you find in
someplace private. Being able to reference what has happened in the past is
invaluable to finding patterns, and you are indeed no exception to this.

A tempting thought, at this point, is to feel terrible: You are to blame for
this situation! If you had just been different, this all could have been
avoided. And so, a note on blame, safety, and humans in complex systems.

## Systems Design and Operator Error

An early, wonderful line in _Engineering A Safer World_ (p. 39) is this:

> All human activity takes place within and is influenced by the environment,
> both physical and social, in which it takes place. It is, therefore, often
> very difficult to separate system design error from operator error: In highly
> automated systems, the operator is often at the mercy of the system design and
> operational procedures.

This has a few implications, but the big three are:

1. The environment around you shapes your actions to the degree that any active
   mistake made is mitigatable by your environment, and
2. Your actions are *well-reasoned* in your context and view on the world, and
   therefore
3. That your decisions *are not to blame*.

To unpack this, let's think about the environment the standard operator that
Leveson is talking about. They're controlling a power plant, or some other
industrial process. They have to navigate controlling an extremely complex
system by their own mental models of this system, informed by the (necessarily
limited) feedback available to them, and can only affect change on this system
by some limited set of actions.

To dig out an old favourite of Safety Engineering nerds, let's talk about the
[Three Mile Island Accident][three-mile-island-wiki]. Many, many analyses, talks
and papers have been written about this, but to be usefully reductive about it,
it came down to a few factors: The sensor they were acting on did not indicate
what the operators thought it indicated (it merely indicated if the valve had
been supplied power, not that it actually had closed), the situation they found
themselves in was never covered in training procedues (but also looked a **lot**
like something they had been trained to *never* let happen), and the feedback
the system was giving them was, to them, contradictory. Their actions, of trying
to diagnose the problem, and their confusion over *whether there even was a
problem to begin with* is perfectly understandable from their contexts as the
event was unfolding.

That, in hindsight, we can see how other indicators could, in theory, have
prevented any damage from being incurred whatsoever, is a meaningless
counterfactual whose main use it is to dictate how people *should have
behaved*/admonish/blame. For their context, their information, situation and
knowledge, they behaved as rationally as they could. To go on and on about
things that *did not happen* is meaningless, and worse, harmful.

So, let's talk about the thing we *can* actually do: Shape our environment to
prevent, mitigate, or lessen hazards that we encounter.

## Environment Design

Our environment is the world we exist in. It presents us events in a certain
way, to which we then react. We can change the ways in which events and facts
are presented to us, and therefore change our reaction.

You can see how this very minimal definition of "environment design" is both,
immensely powerful and absolutely unhelpful.

The core helpfulness comes from shifting attention and consideration from when
we can afford to spare it (times of quiet and rest with little demand on our
facilties) to those when we can't (When we have problems to solve, like when we
are late, or need to think through a problem, or are talking to people).

One of the simplest ways in which you can design your envionment to shift
attention and consideration is locality: If you are prone to forgetting your
lunch, putting it next to the door to grab easily when you are rushing out of
the door makes you less prone to forgetting your lunch.

**TODO**: add another example, and more elaboration here. Talk about
replacement and change over addition.

## The Cycle Of Error

Something to be aware of, and to beware of is what Dr. Cook called *The Cycle of
Error*: A bad thing happens. We look at the bad thing, and find that it was
caused by a person misjudging something, doing something wrong, missing
something crucial in their evaluation. Then we Fix This™. This is usually done
via process, by special-casing this somehow. We add an item to a checklist. We
have Fixed The Issue™.

But in doing so we've made the system more complex. There's now an additional
item to pay attention to. Because the fix was intended to fix one specific
issue, that's the only thing it has been evaluated against, while in many more
other circumstances it may now be a problem. Then, for a while, nothing
happens. We feel assured in our correction of the problem.

Then, one of the situations arises where the correction is actually in the
way. Either the person is able to cope with the increased complexity and is able
to disregard the correction when it is appropriate (which will go unrecognised,
since the correction happening has not resulted in anything visible), or the
correction causes a bad thing to happen, and we again, Fix This™. You can see
where this is going.

## Economic pressures and depression

### Notes

- Instead of economic pressures pulling us away from safety it's depression and
  lack of energy
  - Given that both, economic pressures and depression result in "do more with
    less" actions, they are roughly equatable.
- Even without depression, the same factors are still present. We want to spend
  less time on things like this. We want to spend more time doing the things we
  enjoy. We want to be gnerally happier.

### Draft


## Why Would I Do This, A Coda

I'm aware this is an unusual angle to take for debugging your own life. I'm
aware it's mechanistic, oddly robotic, and detached. That is in fact, why I
recommend this to anyone seeking better understanding of their life:

- The process being mechanistic and checklist-able means that I was able to
  follow it even at my most depressed,
- The detachment allowed me to avoid my own biases towards myself, I was able to
  just treat myself as another person, a difficult task at times.

I do actually recommend this process widely, by applying it to just 1-2 things
that have happened recently, you may be able to gain insight into things you
were not aware of previously.


[^1]: This is a fantastic book, and it's even accessible for free under [the
    Open Access programme][easw-pdf] from MIT Press. Read it, particularly Part
    I is some of the best writing on what it means to engineer I've seen.

[^2]: Caveat for the well-read reader: The field is a lot bigger than that, and
    in particular she seems to have a distinction between systems design and
    systems operation that most of the field does not seem to share. In that, my
    view on this may be limited.

[^4]: Removing myself from consideration and instead considering it an abstract
    person running someone's life (depersonalising it) helped me apply the
    empathy I feel towards people in the abstract, but not necessarily always to
    myself. The same might apply to you.

[^5]: Of which one of the better books on accident modelling happens to be
    *Engineering A Safer World*!

[^6]: Well-read readers will recognise this as the boundaries in Rasmussen's
    Dynamic Safety model, which is usually the model of choice to demonstrate
    how systemic factors in dynamic systems combine to failures.

[^7]: This is something that actually has reached mainstream awareness, in form
    of the now-relatively-well-known term "Psychological Safety", or feeling
    safe to voice your opinions and feedback.

[^8]: While this requires an awareness of your emotions that you may not have to
    this degree, you can then also add the required hazard of "I was unaware I
    was frustrated and irritable", which instead has the mitigation strategy of
    finding ways to take more accurate stock of your emotions.

[^9]: Why this post? I have no other motivation, other than I could successfully
    adapt and apply quite a few techniques to my daily life, and I want to
    share. Between depression, recently-treated ADHD, and PTSD, life is not
    always the easiest, and I will take help from any corner I can.


[easw-pdf]: https://direct.mit.edu/books/book/2908/Engineering-a-Safer-WorldSystems-Thinking-Applied
[three-mile-island-wiki]: https://en.wikipedia.org/wiki/Three_Mile_Island_accident

### Draft Notes

- Remember, the purpose of a system is what it does, there is no inherent virtue
  in what is happening now, and tinkering with it might only yield benefits.
