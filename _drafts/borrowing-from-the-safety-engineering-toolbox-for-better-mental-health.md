---
layout: post
author: Mordecai
title: "Borrowing From The Safety Engineering Toolbox For Better Mental Health."
date: Sat, 30 Oct 2021 23:31:09 +0200
categories: post
---

I recently read _Engineering A Safer World_[^1] by Nancy Leveson, and while
it is intended about how to make systems safe for the people running them, I
can't help but notice that so many of the tools, assumptions and structures
given hold up for the personal life, too. The benefit of the theory of the
really abstract (like systems theory is) is that you can apply it to a lot of
things.[^2] So, an application of systems theory to a personal life impeded by
mental illness and life in These Days.

## The Definition Of Safety In The Context Of Running Your Own Life.

Traditionally, *Safety* means that a system does not do harm to people. In the
system of yourself, operating in the world as it is today, it means not letting
*yourself* come to harm. The same techniques used for eliminating unacceptable
losses in complex systems hold for personal lives, seeing as you are a person in
a complex system: Society. This means we can steal a lot of tools that have been
developed with the urgency and importance of saving lives for saving our own.

Of course, if we consider society the system under scrutiny, we are not going to
get far, society at large is far outside of our influence. Instead, let us draw
a smaller boundary: One person's life, your own. There is considerable discourse over
whether or not one person's life is considered "controllable", but, in the
interest of time, let us settle for "you have some degree of influence over your
own life".

## Hazards

Now that we have a system under consideration, we can start applying from the
toolbox. First up, the identification of hazards.

A *hazard* is anything that, together with a certain set of other events,
produces an accident, a loss, something going wrong that you'd really rather
didn't. Some of these are always present but not helpful to include in a list
intended to mitigate the effects of the ones we can control most.[^11]

The things that fall into this for our interest, are what are typically
considered *symptoms* of something else, things like:

- Poor sleep or insomnia,
- Insufficient/bad/excessive eating,
- Substance-based coping, like alcohol, nicotine, weed, etc,[^12]
- Chronic fatigue,
- Ennui.

It should be pointed out that all these are not harmful or direct problems for
themselves. They tend to be harbingers, signs of other things. They may be not
fun to go through, not exactly wonderful to experience, but only in the most
extreme forms do they do acute harm by themselves. However, all of them open up
the possibility of things going more wrong than if they were absent. Lack of
sleep produces lapses in attention and cognitive capacity that can be mostly
fine, but deadly when combined with driving a car. Chronic fatigue is survivable
but impairs your decision-making substantially, usually with outcomes you'd
rather avoid.

This increased potential for things going wrong is why we want to keep an eye
out for them: If we can avoid these being present in our life, less things have
a possibility of causing an unacceptable loss, and so less things will have the
chance to go wrong.

## Incident Analyses

This is where the second part comes in, the *incident analyses*. You'll almost
certainly remember situations, encounters, missed opportunities that you wish
had gone different. Fights you've had where you felt like an idiot the entire
way through because you were fighting tooth and nail for something you didn't
care about much in the first place. Falling out of touch with friends because
life kept getting in the way. From these situations you can then learn about
your behaviour, how you react, what you do, how you see the world, and how you
prioritise.

The information and behaviours in these events is different (and therefore
useful) from what you know and assume about yourself. This is not the
hypothetical "this is what I think I'd do" person that exists in your head, but
the tired, cranky and ill person that has to deal with life on a daily basis.
This is the person that others are talking to, and the person whose actions form
your context.

I find that some distance to this person actually helps, here. It's about having
empathy with someone, knowing only their external behaviours. We may be able to
see into our own head, but we can't do the same for a depressed friend. If we
want to account for how others react to us, we can't take our thoughts, intents
and wishes into account on how our actions should be seen.


### An Aside About Managing Your Own Psychology

It should be noted here, we are so far looking exclusively at things that have
gone wrong here. We see "things that actually happened" as containing more
valuable information on how you prioritise, act, and decide in the moment than
what you tell yourself in the moment. This can and will clash sharply with your
own self-conception, of how you act. This is, no doubt, painful. It's of
absolutely utmost importance that you do not beat yourself up about this, as
much as you can manage not to. Blame, judgement, and disciplinary 'punishment'
is absolutely antithetical to the entire process, and will make most of the
benefits of it vanish into a puff of misery, but more on this in a bit.

The core idea with anything centred on changing a system is persistence.
Systems are slow to change, this is an intrinsic guard against errant signals
and aberrations. It also means that persistence is key. Keep going, keep
changing little things, and stick with them. Filling yourself with agony and
grief over the things you did wrong, what you could have done better, what was
left undone prevents this exact process from happening.

While this is an immensely useful toolbox, its usual focus on the negative takes
a large psychological toll and therefore has a sort of "you must be this well to
participate" barrier to entry. Instead, try applying the same techniques to
things you think went well, things that left you feeling warm and fuzzy on the
inside. The result will be the same, but with encouragement of the environmental
circumstances rather than management or avoidance.

The general guideline is, when something went very differently than you planned,
foresaw, or thought it would go, it makes for a great context to put into this
process. The key is surprise: How you thought the world worked and how it
actually works didn't match up, why? What can you learn from the difference? Do
you see yourself as a worse person than your friends do? How should that
influence your behaviour? We all play roles, but writing your script yourself
might give you more agency and freedom of experimentation.


## A Worked Example: A Fight With A Friend.

Consider now what happened in this hypothetical interaction. Things did not go
as you planned: "I lashed out at my friend and now they're hurt and I feel
terrible".

There is the obvious first layer here: I erupted at my friend, that is bad and I
should never do this. In order to achieve this, you could begin to view anger as
suspicious, frustration as suspicious, and tamp down on any displayed negative
emotions. This attempted fix for the situation would now have made your life
*worse*, as you suppress your own emotions, in an attempt to correct for some
emotions sometimes being the problem[^14]. You would begin to view *yourself* as the
problem, you blame yourself, and you want to come up with elaborate mechanisms
and tools to prevent this from ever happening again.

Instead, I would encourage you to look at the factors which would need to be
present in order for this to happen:

- You were feeling irritable and frustrated.
- You were talking to your friend.
- Your friend poked at something that you were feeling very self-conscious
  about.

It took all three of these factors to produce the situation, any combination of
two out of three would not have been sufficient, and would not have resulted in
the problem. Accidents in complex systems always require a combination of
factors, only jointly sufficient.

Two of those (1 and 2) involve things that your friend had nothing to do with,
but were nonetheless necessary for this to happen. Those qualify as hazards:
They were necessary for the accident to happen, and the accident would not have
happened without.

You now have mitigation strategies for preventing situations like this from
happening again:

- Find ways to cope with irritability and frustration before it gets exposed to
  other people and potentially results in this.[^8]
- Talk to said friend about this particular topic, ask to avoid it, or to make
  it clear in a way that the same comment/situation does not repeat.
- A step further that comes with more effort and is only worth it if the topic
  has caused issues repeatedly: Sit down and figure out a way you can defuse it.
  Attend therapy, read books, etc.[^10]
- Cancel on your friend when you are feeling irritable and frustrated, as a last
  resort.

After this, you can "zoom out", and focus on the next level upwards. Why were
you frustrated? Is it a regular occurrence? What causes it? How can you get
better at dealing with it? Why did your friend poke at this specific thing? Has
it been a problem in the past? How is your relationship with this friend? And so
on. Each question will yield understanding over how you work and behave, and you
can learn about yourself and your own behaviours.

You should write down the questions you ask, and the answers you find in
someplace private. Being able to reference what has happened in the past is
invaluable to finding patterns, and you are indeed no exception to this. The
guiding principle is a gentle curiosity. How do things work, why do they work?
What has led them to be like this? There's no wrong answers here, merely
explanations for how things came to be, and maybe also how they work. The idea
is to cultivate a curiosity about how things work, what causes you to feel which
things.

Now, it's tempting, when looking at these, to single out the actions of
individual people as "at fault", or "to blame". The reality is always more
complicated than fault, and blame.

## Systems Design and Operator Error

An early, wonderful line in _Engineering A Safer World_ (p. 39) is this:

> All human activity takes place within and is influenced by the environment,
> both physical and social, in which it takes place. It is, therefore, often
> very difficult to separate system design error from operator error: In highly
> automated systems, the operator is often at the mercy of the system design and
> operational procedures.

This has a few implications, but the big three are:

1. The environment around you shapes your actions to the degree that any active
   mistake made is mitigatable by changing your environment, and
2. Your actions are *well-reasoned* in your context and view on the world. This
   is called **local rationality**, for the information, context, values,
   priorities, conflicts that you have, your decisions represent what you
   believe to be the best choice.
3. That your decisions are not to blame, because blame is constructed *after
   the fact*, not when the decisions are actually being made.

To unpack this, let's think about the environment of the standard operator that
Leveson is talking about. They're controlling a power plant, or some other
industrial process. They have to navigate controlling an extremely complex
system by their own mental models of this system, informed by the (limited)
feedback available to them, and can only affect change on this system by some
limited set of actions. They want to do whatever they can to make sure nothing
bad happens, and everyone goes home at night, and comes back to having a job the
next morning.

To dig out an old favourite of Safety Engineering nerds, let's talk about the
[Three Mile Island Accident][three-mile-island-wiki] (TMI). In the TMI accident,
a nuclear power plant experienced a partial core meltdown and the release of
radio-active material outside the containment area. Even if this ended up going
with as little consequence to humans as can be hoped for, it is still an
operational disaster that could have affected many more lives than it did.

Many, many analyses, talks and papers have been written about this, but to be
usefully reductive about it, it came down to a few factors: The sensor they were
acting on did not indicate what the operators thought it indicated (it merely
indicated if the valve had been supplied power, not that it actually had
closed), the situation they found themselves in was never covered in training
procedures (but also looked a **lot** like something they had been trained to
*never* let happen), and the feedback the system was giving them was, to them,
contradictory. Their actions, of trying to diagnose the problem, and their
confusion over *whether there even was a problem to begin with* is perfectly
understandable from their contexts as the event was unfolding.

To say that, in theory, there were other indicators of the situation that could
have led them to successfully avoid any problem whatsoever is a meaningless
counterfactual. You already know the outcome. You already know that
their actions resulted in this. When you know the outcome, you are subject to
Hindsight Bias, and you will criticise their actions far more intensely than you
ever would if you knew the outcome was positive.

To focus on their "faulty" actions, to cry "why didn't they just..." is to blame
the people involved, the people that acted to the best of their information,
skill and resources, is to want to remove the pain and horror you are feeling at
the accident having taken place, and to instead place it on the operators that
"did it wrong".

For the context of the operators, their information, situation and knowledge,
they behaved as rationally as they could. They did everything they could to make
sure nothing bad would happen. To go on and on about things that *did not
happen* is meaningless, and worse, harmful. The operators involved wanted
nothing more than to assure everyone's safety with all of their capacity. The
environment they existed in, *the design of the system* led them to reach the
conclusions they did about the state of reality.

Blame, in general, only makes things worse. It's an understandable human
instinct: Blame exists to discharge pain, discomfort, guilt. There's a single
responsible person, and if we can blame them, that means that are aren't to
blame for this. We avoid the pain and discharge it to someone else instead.

But doing so does nothing to actually address the problem. If someone else is to
blame, and we definitely are not, then our actions haven't contributed to the
problem, and therefore there is no need to change our actions, our environment.
Blame *reduces* our chances to learn from what happened. This is how you end up
with some systems produces monthly occurrences of "unpreventable and tragic
instances of human error". Nothing about it was unpreventable, but to recognise
would mean to do away with the guilt-and-pain-discharging application of blame.

At the beginning of every investigation into an accident stands the decision of
whether we want to do what we can to reduce the chances of further accidents
happening, or if we want to find 'the guilty party' to discipline and 'hold
accountable'. Similarly, you have the choice between blaming, and improving the
safety in your own life. One of those reduces the amount of harm inflicted on
people, I suggest that one.

So, having made that decision, let's talk about the thing we *can* actually do:
Trying to gather as much data to understand _how_ the accident came to be, and
then shaping our environment to prevent, mitigate, or lessen hazards that we
encounter. Because if "unpreventable and tragic human error" happens repeatedly,
the environment is the thing in common between those.


## Environment Design

Our environment is the world we exist in. It presents us events and facts about
the world in a certain way, to which we then react. We can change the ways in
which events and facts are presented to us, or, alternatively phrased, design our
environment differently, and therefore change our reaction.

You can see how this very minimal definition of "environment design" is both,
immensely powerful and absolutely unhelpful. It is general enough to encompass
all of human behaviour, and therefore gives you absolutely nothing you can apply.

It becomes useful when we see how this allows the shifting of attention and
planning from when we can afford to spare it (times of quiet and rest with
little demand on our facilities) to those when we can't (When we have problems
to solve, like when we are late, or need to think through a problem, or are
talking to people). If we can change the structure of events and facts presented
to us, we can change our behaviour without needing to worry about how we behave
in the moment itself, our environment will lead us to reach different
conclusions.

The main principle here is the direction of your attention when we are in the
process of doing things. We can think about ourselves in the situations where
our environment led to our attention being misdirected or lead down dead ends.
What are the things we need to see in the moment? How do we set up the
environment for seeing the information that should guide our decision-making and
as little of everything else as possible?

For example, one of the simplest ways in which you can design your environment
to shift attention and consideration is proximity: If you are prone to forgetting
your lunch, putting it next to the door to grab easily when you are rushing out
of the door makes you less prone to forgetting your lunch. Your attention is
being directed to the lunch at the time you most need it, before you leave your
apartment. Another is timeliness, being reminded of picking up your prescription
when you pass by the pharmacy is more valuable than being reminded of that just
before going to bed.

In digital contexts, something else would be removing notifications from contexts and
situations when they only distract, in others, it would be adding notifications
for events. Getting an email when you haven't bought groceries in a week is
good systems design: Your attention is being redirected to your fridge being
almost empty, but ideally before it runs out. Setting up the sending of this
email is something that we can then do when we have spare resources to help us
when we don't.[^15]

This is also where the analyses come in, what went wrong, where? These point to
weaknesses in the environment setup, and these usually surprise is – our
planning, thoughtful self did not anticipate those things become problems.
That's both, perfectly okay, and completely expected. What we select for in calm
and quiet is never the same as what we select for when in the context of doing
things.

All of these questions are just as valid for asking "What went right?" as well
as asking "What went wrong?". Clearly we thought things would turn out different
than they did.

We don't fully control our environment. One particular, emotional failure mode
I've run into with this model is, well, if I can setup my environment to avoid
this, this means that not doing so is my mistake yet again and I've fucked it
up, *again*. This is not helpful, and will just make you feel worse. The
environment is not totally under your control. But you can influence it,
carefully.

## The Cycle Of Error

Something to be aware of when you do actively influence your environment (and to
beware of) is what Dr. Cook called *The Cycle of Error*: A bad thing happens. We
look at the bad thing, and find that it was caused by a person misjudging
something, doing something wrong, missing something crucial in their evaluation.
In other words, "Human Error". Then we Fix This™. This is usually done via
process, by special-casing this somehow. We add an item to a checklist. We have
Fixed The Issue™.

But in doing so we've made the system more complex. There's now an additional
item to pay attention to, we've added cognitive overhead. Because the fix was
intended to fix one specific issue, that's the only thing it has been evaluated
against, while in many more other circumstances it may now be a problem. Then,
for a while, nothing happens. We feel assured in our correction of the problem.

Then, a situations arises where the correction to the original problem is
actually in the way. Either the person is able to cope with the increased
complexity and is able to disregard the correction when it is appropriate (which
will go unrecognised, since the correction happening has not resulted in
anything visible), or the correction causes a bad thing to happen, and we again,
Fix This™. You can see where this is going.

This is particularly pernicious in situations where it's people dealing with
people, and an edge case crops up. People (especially engineers are prone to
this[^16]) rush to fix the edge case with additional process, but the cost of the
additional complexity in process is so much higher than the problem it solves.
[Jacob Kaplan-Moss][jkm-story] recently made this point better than I would in
this paragraph.

## Economic pressures and depression

One of the many reasons as to why the world is so hard to deal with – I would
argue one of the central ones – is that complex systems are dynamic. They adapt
to the pressures they face. In abstract, big systems that are studied like this,
with formal incident reviews processes, people employed solely to evolve the
system design, the pressures are economic: The system costs too much money, the
system doesn't produce enough, the system hurts too many people.[^6]

And the system adapts. The people contained within find ways of adapting to
those pressures. They find ways to be safer, cheaper, faster. The system, first
of it all, optimises for its own continued existence. Everything else comes
second. The problem is that applying these pressures will produce consequences
that are usually not foreseen, or intended, by the parts that apply these
pressures. Pressuring a system to be cheaper will result in adaptations that
The Powers That Be would consider "cut corners".[^17]

The second part to this adaptation and complexity is the _Law Of Stretched
Systems_. In terms of the above, if you have a system with 'spare capacity',
i.e. a system that could produce more, then the pressure towards efficiency will
demand that production. And it will demand more, and more, until all of that
spare capacity is used up, and the system is just, just on the verge of being
too expensive, too slow, too dangerous. Now, any further capacity, like someone
inventing a more efficient process, and any slack you add to the system and
don't have a means of defending with tooth and nail will instantly be eaten up
by this demand. After all, the factory owners ask themselves, why make less money?

All of these pressures persist when we apply this lens to a person's life
instead, trading some factors for others. Even if you do not suffer from mental
illness, you are still subject to these pressures. You still want to be happier,
healthier, wealthier.

Mental illnesses have a habit of being, well, not good for you. We'd like them
to not existing in our head. They are additional drains on your resources, they
make your system more expensive to run, slower, or more unsafe, and honestly,
most do all three. It may sound trivial to say, but if you are aware of having
one , _you have to account for it_. Planning as if they would not be a thing
will end up getting you in ways that make everything even worse, afterwards.


## The Importance Of The "Measuring Channel"

The "Measuring Channel" is a bit of an abstract term that describes the flow of
data from the front lines, the sharp end, to the decision-makers and planners,
the blunt end. It's how you figure out how close you are to the boundaries that
you operate in. All your decision-making lives and dies by the information you
get from this channel, you are blind to what's happening otherwise.

This also transfers to your own life. We have some measuring channel, we notice
hunger and decide to eat, we notice anger and vent it somewhere safe, we notice
desire for something and buy it. Everyone has an information flow from the sharp
end (your body, emotions, active-doing-of-stuff practical self) to the blunt end
(the planning, project-managing logical self).

Sadly, mental illness has a habit of messing with this. We forget to eat, we
don't recognise our emotions and then do things we regret. The quality of our
measuring channel has degraded to the point where we can't make "good" decisions
(as judged in hindsight), because the data we have does not reflect reality well
enough for that. For the data we have, drinking a bottle of vodka would be a
valid choice. (c.f. local rationality from above)

But, you can improve that! And it's a smart investment, with high returns for
the effort expended. Getting better data from the world is valuable in illness
as it is in health. Working on reducing the difference between how you think the
world works, and how it has been shown to work is universally useful. This can
be done in small ways, like making explicit small predictions about how
something is going to make you feel or how people are going to react, and then
checking.

Write things down. Words don't (or rarely) change when you're looking away. Your
mental context may change, but the words you wrote in this context won't. This
helps you figure out the *how*, how you interact and influence your life. Being
able to refer to things you wrote down at the time of something unpleasant
happening is a sight into your brain at the time, something you usually don't
get. Take advantage of it, write things down.

"Getting in touch with yourself" is a (thankfully) popular thing to do, from
journaling to meditation to IFS. Personally, for me, journaling and meditation
work, but everyone is different here. Try out tools, see what helps you the
most. Just don't get stuck only looking at the tools. You're trying different
tools to solve problems you face, the effect is more important than the
tool.[^13]


## Why Would I Do This, A Coda

I'm aware this is an unusual angle to take for introspection and debugging. I'm
aware it's oddly robotic, dehumanising and detached. It sees people, or
yourself, as a system that does what it does, not as a person. That is in fact,
why I recommend this to anyone suspecting their brain working similar to mine,
or finding some kind of resonance in these words and processes.

The detachment allowed me to avoid my own biases towards myself, I was able to
just treat myself as another person, a difficult task at times. The focus on
environmental factors helped me get out of the cycle of blaming myself, of
making myself feel worse when I already was unwell. We are but a part in the
system, and as such, we are subject to its influences. To deny our influences is
to deny our humanity, to disconnect us from other people. In consequence,
treating our actions as free from such influences is illogical and imports a lot
of pain you don't need to suffer.

Most importantly for why it works, it meets us where we are. Most advice, like
making a spreadsheet, meditating and working out are indeed things that would
improve our state when we're at our worst. However, they are so far our of reach
for being actionable and usable advice that they border on insulting. When we
can't cook dinner for ourselves and sleep 3 hours per night, advice of "go to
the gym" produces, at absolute best, a tired laugh. But exactly that is where
environment design helps most, by helping us reach better outcomes without
needing to expend resources when we can least afford it. This is applicable
regardless of mental illness -- everyone has days where the prospect of Doing
The Thing is of comparable effort to climbing a mountain. But maybe, this will
give you a pointer or two for taking the first step.

---

[^1]: This is a fantastic book, and it's even accessible for free under [the
    Open Access programme][easw-pdf] from MIT Press. Read it, particularly Part
    I is some of the best writing I've seen on what it means to be an engineer.

[^2]: The downside of the really abstract is that it needs quite a lot of work
    to apply to anything.

[^6]: Well-read readers will recognise this as the boundaries in Rasmussen's
    Dynamic Safety model, which is usually the model of choice to demonstrate
    how systemic factors in dynamic systems combine to failures.

[^8]: This requires considerable knowledge of yourself and of your own emotions,
    but this can be a very difficult skill to acquire. Don't fret if your
    reaction is to wonder how the hell you would do that. It's a learnable skill
    like many others. David MacIver wrote a wonderful post about getting started
    with this [here][drm-alexithymia].

[^10]: Please don't take this to mean that you are at fault for this reaction,
    or that it "shouldn't even be a problem", or that it's bad to be angry at
    what the topic. I mean this purely in the sense of, if you can find ways to
    avoid being annoyed, you end up less annoyed. For me, one of these cases was
    a direct trigger for my PTSD and I lashed out in consequence. Should I have
    been angry? Yes. But it also hurt people that did nothing to contribute to
    my pain, and hurting them did nothing to lessen my pain. Learning how to
    defuse that made my life better.

[^11]: Being outside comes with the small-but-present risk of being mauled by a
    bear, that doesn't mean that you shouldn't go outside, but it *also* doesn't
    mean that you should ignore the possibility of Surprise Bear.

[^12]: The frequently-ignored point about substance-based coping is that it
    *still (for the most part) achieves its main goal*, coping with the broader
    context in life. Coping is not a dirty word, it's how you deal with life.
    The these-days common derogatory use of "cope" and "copium" makes me sad, we
    all need to deal with the world in some form. Some forms of coping are
    healthier than other forms of it, but all of it serves the purpose of
    dealing with the world. I just also consider it necessary to be aware of
    *how* you cope with the world, and to be aware of its limitations.

[^13]: Looking specifically at the people here who read about Luhmann's
    Zettelkasten and now have abandoned all original projects to focus solely on
    the best note taking strategy.

[^14]: The problem with suppressing emotion is not the lack of negative emotions,
    it's that suppressing them disconnects you from your feeling altogether,
    feeling joy and happiness becomes equally as hard as feeling the anger you
    have laboured so hard to lock away. This is like gasoline on depression's
    lit match.

[^15]: This is why I consider [software to be brain prostheses]({{
    '/2021-11-22/software-as-brain-prosthesis' | relative_url }})

[^16]: I believe this is because computers generally don't mind additional logic
    that much - the code of most production software application is error
    handling and "unhappy" paths. This is fine there, but does not work well
    with people.

[^17]: This is also where blame comes in: The system pressures the people
    operating it to be cheaper, but the only way to do so ends up making them
    liable for "cutting corners". After that, they're the ones blamed.

[easw-pdf]: https://direct.mit.edu/books/book/2908/Engineering-a-Safer-WorldSystems-Thinking-Applied
[three-mile-island-wiki]: https://en.wikipedia.org/wiki/Three_Mile_Island_accident
[jkm-story]: https://jacobian.org/2022/feb/14/that-wild-aam-story/
[drm-alexithymia]: https://drmaciver.substack.com/p/labelling-feelings
